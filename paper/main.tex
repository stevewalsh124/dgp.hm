\documentclass[11pt]{article}
\usepackage{hyperref}
\usepackage{amsmath, amsfonts, amssymb, mathrsfs, dsfont}
\usepackage{dcolumn}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{filemod}
\usepackage{natbib}
\usepackage[ruled, vlined]{algorithm2e}
\usepackage{floatrow}
\usepackage{setspace}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{bbm} % for indicator function
\usepackage{xcolor} % only for coloring text while revising

\hypersetup{
    colorlinks=true,
    linkcolor=blue, 
    urlcolor=black,
    citecolor=blue, 
    }

\oddsidemargin=0.25in
\evensidemargin=0.25in
\textwidth=7in
\textheight=8.75in
\topmargin=-.5in
\addtolength{\oddsidemargin}{-.5in}
\addtolength{\evensidemargin}{-.5in}
\footskip=0.5in
%\doublespacing

\title{Bayesian Deep Gaussian Processes for Correlated Functional Data: \\
        A Case Study in Cosmological Power Spectra}
\author{Stephen A. Walsh\thanks{Corresponding author: Division of Natural Sciences, 
        Math and Technology, Elms College, {\tt walshst@elms.edu}} \and 
        Annie S. Booth\thanks{Department of Statistics, Virginia Tech} \and
        David Higdon\footnotemark[2] \and
        Marco A.R. Ferreira\footnotemark[2] \and
        Jared Clark\footnotemark[2] \and
        Kelly Moran\thanks{Los Alamos National Laboratory} \and
        Katrin Heitmann\thanks{Argonne National Laboratory}}
\date{\today}


\begin{document}

\maketitle
\bigskip

\begin{abstract} 
Understanding the structure of our universe and the distribution of matter is an 
area of active research.  As cosmological surveys grow in complexity, the development 
of emulators to efficiently and effectively predict matter power spectra is essential.  
We are particularly motivated by the Mira-Titan Universe simulation
suite which, for a specified cosmological parameterization (termed a ``cosmology''), 
provides multiple response curves of various fidelities, including correlated 
functional realizations.  Our objective is two-fold.  First, we estimate 
the underlying true matter power spectra, with appropriate uncertainty 
quantification (UQ), from all of the provided curves.  To this end, we propose a 
novel Bayesian deep Gaussian process (DGP) hierarchical model which synthesizes 
all the simulation information to estimate the underlying matter power spectra
while providing effective UQ.  Our model extends previous work on Bayesian DGPs 
from scalar responses to correlated functional outputs.  Second, we leverage our predicted 
power spectra from various cosmologies in order to accurately predict the entire 
matter power spectra for an 
unobserved cosmology.  For this task, we use basis function representations 
of the functional spectra to train a separate Gaussian process emulator.  
Our method performs well in synthetic exercises and against the benchmark cosmological 
emulator (Cosmic Emu).
\end{abstract}

\noindent \textbf{Keywords:} computer experiment, Cosmic Emu, 
principal components analysis, Mira-Titan, surrogate, uncertainty quantification

%\vfill

\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%To further our understanding of the structure and movement of the universe, 
%researchers utilize numerous cosmological surveys such as the Sloan Digital Sky 
%Survey \citep{york2000sloan} and the upcoming Nancy Grace Roman Space Telescope 
%\citep{Dore2019WFIRST} which are continuously growing in complexity. With these 
%tools, cosmologists aim to continue learning more about cosmic acceleration 
%\citep{caldwell2009physics}. To this end, one important ingredient to aid in this 
%understanding of our universe is the matter power spectrum. 

Computer simulation experiments are invaluable tools in the study of cosmology.
Experiments which simulate the expansion of the universe are growing
in prevalance and complexity \citep[e.g.,][]{lawrence2010coyote,derose2019aemulus,
nishimichi2019dark,angulo2021bacco,euclid2021euclid,moran2023mira}.  
We are particularly motivated by a simulation
of the matter power spectrum, which describes the distribution of matter as a 
function of spatial scale. 
%It is often represented as a function of wavenumber $k$ (units Mpc$^{-1}$), which is 
%inversely related to spatial scale. 
On large scales, power spectrum behave according to linear perturbation 
theory \citep{pietroni2008flowing, lesgourgues2009non}.  On smaller scales, nonlinear 
dynamics require the use of computationally intensive simulations, yielding
correlated functional data.
%the Coyote Universe \citep{lawrence2010coyote} and the Mira-Titan Universe \citep{moran2023mira} 
%are two simulation suites dedicated to this effort.  
Our overarching goal is to leverage such simulation data to 
first estimate and then predict underlying power matter spectra for various 
cosmological parameterizations.

The Mira-Titan simulation suite \citep{moran2023mira}
defines ``cosmologies'' according to eight cosmological parameters (more on this
in Section \ref{sec:data}).  For a particular cosmology, the simulation of the power matter spectrum 
is rather complex.  Although we presume there exists some true matter spectrum as a function
of wavenumber, we are not able to directly observe it.  Rather, the simulation returns
a convoluted patchwork of potential spectra, which vary in fidelity and are only trusted
over particular wavenumber ranges.  Our first objective is to synthesize expert knowledge
and all available simulation information into an effective estimate of the true underlying
matter spectrum.  

There are several challenges to estimating the underlying spectrum.  Our model
must: handle multiple correlated functional observations, offer enough 
flexibility to accommodate the nonstationarity present in power matter spectra 
(which vary in smoothness across wavenumbers), provide effective uncertainty
quantification (UQ), and allow for the incorporation of expert knowledge 
regarding the wavenumbers over which various outputs are trusted.  To this end, 
we propose a Bayesian hierarchical model which treats functional simulation 
outputs as realizations of a Gaussian process (GP) 
centered on the true underlying spectrum, which itself is a realization of a deep Gaussian process 
\citep[DGP;][]{damianou2013deep}.  The GP accommodates correlated observations
through its covariance structure.  The depth of the DGP offers nonstationary
flexibility.  The Bayesian framework facilitates UQ and the incorporation of prior
knowledge.  While Bayesian DGPs have been previously deployed for computer experiments 
with scalar responses \citep[e.g.,][]{sauer2023active,sauer2023vecchia,ming2023deep}, 
they have yet to be extended to correlated functional outputs. 
To demonstrate the profiency of our Bayesian hierarchical DGP, 
we benchmark its performance in two unique settings: with synthetic data 
mimicing the Mira-Titan data and with real-world data from 
the Code for Anisotropies in the Microwave Background \citep[CAMB;][]{lewis2011CAMB}.
The CAMB model exhibits similar behavior to Mira-Titan but crucially
provides a ``true" power spectrum for each cosmology.

Our second objective is to leverage simulation data from a limited set of
cosmologies in order to predict power matter spectra for unobserved cosmologies.
Due to the computationally expensive nature of the Mira-Titan simulation suite
(one batch of simulations can take multiple weeks to run on a supercomputer),
it is infeasible to evaluate the simulation for every possible eight-dimensional
cosmological configuration which may be of interest.  Instead, we desire
a statistical ``emulator'' or ``surrogate model'' 
\citep{santner2003design,gramacy2020surrogates} which will provide quick and effective
predictions of power matter spectra for any cosmological parameterization.
\citet{moran2023mira} provide a state-of-the-art emulator for the Mira-Titan
simulation suite, which was trained on 117 simulations, and is termed 
the ``Cosmic Emu.''\footnote{\url{https://github.com/lanl/CosmicEmu}}
We leverage the same training data, in conjunction with our Bayesian hierarchical
DGP model and basis function representations, to train a GP surrogate 
on principal component weights in order to predict spectra for unobserved
cosmologies \citep{higdon2008computer, higdon2010estcosmo}. 
Our method compares favorably to Cosmic Emu on held-out cosmologies.

The remainder of the paper is organized as follows.  Section \ref{sec:data} 
introduces our motivating application, the Mira-Titan simulation suite.  
Section \ref{sec:hm_fit} describes our hierarchical Bayesian DGP and 
validates its performance on synthetic exercises and the CAMB simulations.  
Leveraging this trained model, Section \ref{sec:pred} details 
our procedure for predicting at unobserved cosmologies, benchmarking against
state-of-the-art competitors on the CAMB and Mira-Titan simulations. 
Section \ref{sec:disc} concludes with a discussion of our contributions and avenues for 
future research.  We provide reproducible code and an {\sf R} package for our 
Bayesian DGP model in a public git repository.\footnote{\url{https://github.com/stevewalsh124/dgp.hm}}
%\textcolor{cyan}{Please note: this repository is currently private until we 
%hear back regarding permissions for sharing the Mira-Titan data alongside our code.}

%Leveraging these simulations allows for emulation and prediction of the matter power 
%spectrum under varying specifications for eight different cosmological parameters 
%(i.e., different cosmologies). Estimating and understanding the influence of these 
%parameters on cosmic expansion are areas of active research. In addition to 
%presenting the Mira-Titan simulation suite, \cite{moran2023mira} builds off 
%of previous spectrum emulation \citep{lawrence2017mira} to provide the final 
%emulator (Cosmic Emu) based on the full suite of 117 batches of simulations. 

%In this work, we expand on the previous emulation approaches and propose a 
%novel synthesis of methods to quantify uncertainty and predict matter power 
%spectra for different cosmologies using deep Gaussian processes (DGPs). In order 
%to handle multiple realizations of functional output (from the Mira-Titan 
%simulation suite), we use hierarchical modeling and basis functions within our 
%DGP framework to accurately estimate and predict power spectra for different 
%cosmologies. 

\section{Mira-Titan}
\label{sec:data}

The Mira-Titan simulation dataset consists of simulated power spectra for 
117 unique cosmologies. Each of these cosmologies is specified by eight cosmological 
parameters: matter density, baryon density, amplitude of density fluctuations, 
dimensionless Hubble parameter, spectral index of scalar perturbations,
dark energy equation of state parameters, and neutrino density. For more details 
on these parameters and their effects, see \cite{dodelson2020modern, aghanim2020planck, heitmann2016mira}. 
Parameter ranges are specified in Table 2.1 of \cite{moran2023mira}.
There is an optional ninth parameter, the redshift, which we fix at 0.
%Different simulation output exists for different values of a ninth value, 
%the redshift; in this work, we fix 
%this value at 0. 

% after \linewidth:, trim=0 13 0 45, clip=TRUE
\begin{figure}[ht]
    \centering 
    \includegraphics[width=\linewidth]{plot_data.png}
    \caption{{\it Left:} The perturbation theory (solid green), low resolution runs (solid grey), 
    and high resolution run  (solid pink) for a particular cosmology. 
    The weighted average of these is shown in dashed orange. Dotted lines at the bottom
    indicate where each data type is deemed approximately unbiased. 
    {\it Middle:} Same as left, but restricted to wavenumber ($k$) values where the low resolution 
    runs are approximately unbiased.
    {\it Right:} Same as middle, but with estimated posterior mean subtracted.
    \textcolor{red}{(@Steve - please fix the legend so it is not going over the lines)}}
    \label{fig:plot_data}
\end{figure}

For each cosmology, Mira-Titan contains a batch of 18 simulated spectra: an inexpensive 
spectrum estimated from linear perturbation theory ($y_p$), 16 spectra estimated from 
low resolution simulations ($y_{\ell_r}, r \in \{1,\dots,16\}$), and one spectrum from 
a high resolution simulation ($y_h$). 
These spectra are represented as a function of wavenumber $k$.  Following 
\cite{moran2023mira}, we model on the emulation space 
$\mathcal{P}(k)=\log_{10}\left(\frac{k^{1.5}P(k)}{2\pi^2}\right)$, where $P(k)$ represents the
original spectra. Output is available for $n=351$ values of $k$, spanning
$0.001 \leq k \leq 5$, but each data type has unique wavenumber ranges
where it is deemed approximately unbiased. For $k<0.04$, only $y_p$ provides a reliable 
estimate of the true spectra. $y_{\ell_r}$ are valid for $0.04 \leq k \leq 0.25$, and 
$y_h$ is valid for $0.04 \leq k \leq 5$.  Figure \ref{fig:plot_data} shows an example 
of the output for a particular cosmology. When we focus on $k$ values where $y_{\ell_r}$ 
is valid (center panel), the spatially correlated errors of the low-resolution and high-resolution runs 
becomes apparent.

Notice, in the center/right panels of Figure \ref{fig:plot_data}, the precision of each
low/high resolution spectra increases as $k$ increases.  The curves get progressively 
tighter from left to right.  We would like to conveniently wrap this domain-specific 
knowledge inside our Bayesian framework later.  To this end, \cite{moran2023mira} 
used the multiple low- and high-resolution spectra across all cosmologies to
obtain precision estimates, $p_1,\dots, p_n$, across the $n$ 
wavenumber values using a log-log regression model. A multiplier $c$ for 
the increase in precision from the low- to high- resolution output is also 
estimated with this regression model. 
\textcolor{red}{(What is the c value?  Can we report it?)}
We use these estimates to define three 
diagonal precision matrices, one for each data type (perturbation theory, 
low resolution average, and high resolution). Specifically, denote $\Lambda_p$, 
$\Lambda_\ell$, and $\Lambda_h$ as the $n\times n$ diagonal matrices with elements
\[
\Lambda_p^{(ii)} = \begin{cases}
    10^5 &\text{for } k_i < 0.04 \\
    0  &\text{otherwise}\\
    \end{cases}
\quad
\Lambda_\ell^{(ii)} = \begin{cases}
    16p_i &\text{for } 0.04 \leq k_i < 0.25 \\
    0  &\text{otherwise}\\
    \end{cases}
\quad
\Lambda_h^{(ii)} = \begin{cases}
    cp_i &\text{for } 0.04 \leq k_i < 5 \\
    0  &\text{otherwise}\\
    \end{cases}
\]
for $i=1,\dots, n$.  In $\Lambda_p$, we use the sufficiently high precision 
of $10^5$ to impose the deterministic nature of the perturbation theory output.
In $\Lambda_\ell$, the multiplication by 16 accounts for the sample size of the
low resolution runs.
We then calculate a weighted average for each cosmology: 
$\bar y = \Lambda^{-1}(\Lambda_p y_p + \Lambda_{\ell} \bar{y}_\ell + \Lambda_h y_h)$, 
where $\Lambda = \Lambda_p + \Lambda_\ell + \Lambda_h$ and 
$\bar{y}_\ell = \frac{1}{16}\sum_{r=1}^{16} y_{\ell_r}$. In Figure \ref{fig:plot_data},
the weighted average is shown in dashed orange.  As an estimate of the true
underlying spectrum, the weighted average fluctuates too drastically.  
This is especially apparent after centering (right panel).
\textcolor{red}{(@Steve - how are we centering?)}
Although the weighted average incorporates all available observatons and 
expert knowledge regarding the precisions, it fails to account for the spatial 
dependence inherent in the smooth but stochastic spectra, which is pivotal to 
effectively inferring the true spectrum.

%We consider a training-testing split with 111 cosmologies used for estimation and 6 
%cosmologies held out for testing.  Our ultimate objective is to effectively predict
%the underlying power matter spectra for the held-out cosmologies based on their 
%8-dimensional input configuration (Section \ref{sec:pred}).  But first, we must 
%obtain effective estimates of the underlying spectrum for each training 
%cosmology (Section \ref{sec:hm_fit}). \textcolor{red}{(@Steve - maybe this is a
%good place to introduce the ``hold out'' and ``within sample'' terms?)}

\section{Bayesian Hierarchical Modeling for Particular Cosmologies}
\label{sec:hm_fit}

Here we describe our first contribution: the use of a Bayesian hierarchical model 
to estimate the underlying spectrum and quantify uncertainty for a particular cosmology.
Let input $X$ represent the vector with elements $x_i = \log_{10}(k_i)$ for $i=1,\dots,n$.
In the previous section, we used lowercase $\bar{y}$ to denote 
the observed weighted average; now, we use $\bar{Y}$ to indicate the corresponding 
random variable within the statistical model.  
%Together, $X$ and $\bar{Y}$ comprise the 
%training data for a particular cosmology. 
$\bar{Y}$ is typically pre-processed
based on domain expertise.  Pre-processing for Mira-Titan was described in Section 
\ref{sec:data}; we will detail pre-processing 
for the CAMB suite in Section \ref{subsec:camb}.

\subsection{Model Specification}

Let $S$ represent the true (but unknown) underlying power matter spectrum for
a particular cosmology.  We consider $\bar{Y}$ a noisy realization of $S$.
Specifically, we assume $\bar{Y}$ is a random realization of a Gaussian 
process centered at $S$ with some covariance, i.e., 
$\bar{Y}\mid S \sim \mathrm{GP}(S, \Sigma_\varepsilon)$.  While previous works
have considered diagonal $\Sigma_\varepsilon$ \citep{moran2024dpc}, we find it
essential to account for the smoothly varying spatial dependence
(as visualized in Figure \ref{fig:plot_data}).  We thus specify a dense 
covariance matrix $\Sigma_\varepsilon$ that simulataneously
allows us to model the correlated errors and build domain-matter expertise
into the prior. To this end, we embrace variations of the Mat\'ern kernel 
\citep{stein1999interpolation}, tailored to each cosmology (more on this in later 
subsections). 

We next place a Gaussian process prior on $S$, i.e.,
$S\sim \mathrm{GP}\left(\boldsymbol{\mu}_S, \Sigma_S(\cdot)\right)$, again with a 
Mat\'ern kernel. Here, we set $\boldsymbol{\mu}_S=\mathbf{0}$, although our model
is applicable to any selection of $\boldsymbol{\mu}_S$. Standard practice would 
use locations $X$ as the inputs to kernel $\Sigma_S(\cdot)$, yet we have found that 
prior to lack sufficient flexibility for our motivating
application.  In the Mira-Titan setting, some nonstationarity is expected due to 
baryonic acoustic oscillations when $-2 \leq \log_{10}(k) \leq -1$. To account 
for this, we incorporate a latent monotonic Gaussian process \citep[monoGP;][]{barnett2025monotonic},
which accommodates nonstationarity by warping $X$ via 
$W \sim \mathrm{monoGP}\left(\boldsymbol{\mu}_W, \Sigma_W(X)\right)$.
$W$ is also an $n$-vector whose entries $w_i$ correspond to warped versions of each $x_i$.
Again, we set $\boldsymbol{\mu}_W = \mathbf{0}$ without loss of generality (we have
found $\boldsymbol{\mu}_W = X$ works similarly).
Ultimately, this yields the following hierarchical model:
\begin{equation}\label{eq:dgphm}
\begin{aligned}
\bar{Y}\mid S,\Sigma_\varepsilon &\sim \mathrm{GP}(S,\Sigma_\varepsilon) \\
S\mid W &\sim \mathrm{GP}\left(\mathbf{0}, \Sigma_S(W)\right) \\
W &\sim \mathrm{monoGP}\left(\mathbf{0}, \Sigma_W(X)\right).
\end{aligned}
\end{equation}
The functional composition of GPs in the latter two lines forms a ``deep Gaussian process'' 
\citep{damianou2013deep,dunlop2018deep}. Additional latent layers could be considered, 
although we find one is sufficient.

For both $\Sigma_S$ and $\Sigma_W$, we use Mat\`ern kernels with unit scale and
unique lengthscales,
\[
\begin{array}{l}
\Sigma_S(W)^{i,j} = k\left(||w_i - w_j||^2, \theta_S\right) \\[7pt]
\Sigma_W(X)^{i,j} = k\left(||x_i - x_j||^2, \theta_W\right)
\end{array}
\quad\textrm{where}\quad
k(d, \theta) = \left( 1 + \frac{\sqrt{5}d}{\sqrt{\theta}} + 
  \frac{5d^2}{3\theta}\right) \exp\left(-\frac{\sqrt{5}d}{\sqrt{\theta}}\right).
\]
In our one-dimensional setting, we embrace unit scale on $S$ to preserve parsimony 
and identifiability with $\theta_S$ \textcolor{red}{(@Steve - can you cite that paper here?)}.
Unit scale on latent $W$ was recommended by \citet{sauer2023active} for similar reasons.

\subsection{Bayesian Inference}

Our inferential goal is to obtain the posterior distribution of 
$S\mid\bar{Y},\Sigma_\varepsilon$, but this requires inferring latent $W$.  
We first integrate over $S$ to condense our hierarchical model of Eq.~(\ref{eq:dgphm}) into
\begin{align}
\label{eq:likelihood}
\bar{Y} \mid W, \Sigma_\varepsilon &\sim \textrm{GP}(\mathbf{0}, \Sigma_S(W) + \Sigma_\varepsilon) \\
\label{eq:prior}
W &\sim \mathrm{monoGP}\left(\mathbf{0}, \Sigma_W(X)\right)
\end{align}
A detailed derivation, including generalizations for 
$\boldsymbol{\mu}_S\neq\mathbf{0}$, is provided in \ref{sec:apdx_int_lik}. 
The incorporation of $\Sigma_\epsilon$ in the
Gaussian likelihood of this outer layer is an essential upgrade to previous DGP inferential schemes.
This covariance incorporates knowledge of the smoothly varying dynamics from which $\bar{Y}$ was
generated.

We embrace fully-Bayesian inference of latent $W$ and kernel hyperparameters $\{\theta_S, \theta_W\}$.
Specifically, we use elliptical slice sampling \citep[ESS;][]{murray2010elliptical} to 
generate posterior samples of $W$, using Eq.~(\ref{eq:prior}) for proposal generation and 
Eq.~(\ref{eq:likelihood}) for likelihood-based acceptance.  
For $\theta_S$ and $\theta_W$, after pre-scaling, we adopt the default prior specifications 
provided in the {\tt deepgp} {\sf R}-package \citep{deepgp}.
We then integrate Metropolis-Hastings sampling of these parameters in a Gibbs framework 
with the ESS sampling of $W$ \citep{sauer2023active}.

Given burned-in posterior samples $\{W^{(t)}$ and $\theta_S^{(t)}\}$
for $t\in\mathcal{T}$ ($\theta_W^{(t)}$ is only used to sample $W^{(t)}$), 
we may leverage Bayes' Theorem to obtain the
posterior distribution of the true power matter spectrum for a particular cosmology as
\[
S^{(t)}\mid\bar{Y}, \Sigma_\varepsilon \sim \mathcal{N}_n(m^{(t)}, C^{(t)})
\quad\textrm{where}\quad
\begin{array}{rl}
C^{(t)}&=\left(\Sigma_S(W^{(t)})^{-1}+\Sigma_\varepsilon^{-1}\right)^{-1} \\
m^{(t)}&=C^{(t)}\left(\Sigma_\varepsilon^{-1}\bar{Y}\right).
% "+\Sigma_S(W^{(t)})^{-1}\boldsymbol{\mu}" removed from m^t when mu=0
\end{array}
\] 
This form is simplified for $\boldsymbol{\mu}_S=\mathbf{0}$; a general derivation 
is provided in \ref{sec:apdx_SgivenY}.  This closed-form enables direct posterior
sampling of $S^{(t)}$.  We draw samples accordingly and compute their average 
to obtain our posterior mean for a particular cosmology. 
Additionally, we quantify uncertainty by finding the 2.5th and 97.5th percentiles 
of the posterior draws at each index to obtain a 95\% credible interval.
We denote our inference procedure for the hierarchical model of Eq.~(\ref{eq:dgphm}) as
``DGP.FCO'' given its deep Gaussian process foundation with additional hierarchical
structure to incorporate functional correlated outputs (FCO).

\subsection{Simulation Study}
\label{subsec:sim}

We compare DGP.FCO to competing models with a simulation study where the underlying 
true curve is known. Following \cite{moran2024dpc}, we consider two test functions 
defined as
\[
\begin{aligned}
  f_1(x) &= m_1 \exp\left(-\frac{u_1x}{2}\right) * \cos\left(x\sqrt{25-\left(\frac{u_1}{2}\right)^2}\right) - \frac{m_1x}{5}\\
  f_2(x) &= \exp\left(-m_2(x-3)^2\right)+\exp\left(-u_2(x-1)^2\right)-0.05\sin\left(8(x-1.9)\right.
\end{aligned}
\]
We consider $x\in[0, 4]$.  For additional variation, the values of $m_1, m_2, u_1,$ and 
$u_2$ are randomly selected from
$m_1 \sim \text{Uniform}(0.5,1.5)$, $u_1 \sim \text{Uniform}(1.5,2.5)$, and $m_2,u_2 
\sim \text{Uniform}(0.6,1.4)$. 
      
For the two variance settings, we consider matrices $\Sigma_A$ and $\Sigma_B$ to 
have a Mat\'ern covariance function with a nugget of $10^{-8}$ and smoothness of 2.5. 
For setting ``A", we have $\tau^2=0.0225$ and $\theta=0.01$. For setting ``B", we have 
$\tau^2=0.1$ and $\theta=0.05$, and additionally scale this covariance matrix by 
a vector of precision values $s$ so that $\Sigma_B = s M s^T$ is nonstationary; here $M$ is 
a Mat\'ern covariance matrix with parameters $\tau^2$ and $\theta$.
\textcolor{red}{(@Steve - this whole paragraph needs re-write.  Need to start saying
how you draw $r$-many realizations from a GP with some mean (?) and some spatially varying
covariance.  Then use something like this:
\[
\begin{aligned}
\Sigma_A &= 0.0225 * k(||x_i - x_j||^2, 0.01) \\
\Sigma_B &= s^\top Ms \quad\textrm{where}\quad M = 0.1 * k(||x_i - x_j||^2, 0.05)
\quad\textrm{and}\quad s = ???
\end{aligned}
\]
where you say $k$ is defined according to the previous equation.  Also, what is s?}

For each simulated function and variance specification, we consider 20 Monte Carlo repetitions
with re-randomized $m_1, m_2, u_1, u_2$.  We consider $r = 5$ and $r = 15$.
\textcolor{red}{@Steve - what is $n$?  How dense is the grid?  I think we need a visual
of this scenario.  Perhaps two panels, one with an $f_1$ and one with an $f_2$.
Show the true function.  Then show $r = 5$ realizations.  Use points to highlight
the training observations.  That way for the other methods, you can comment on how
they treat the points as all the same, not coming from 5 smooth curves.}

\begin{figure}[t]
    \centering
    \includegraphics[width=6in]{sims_logS.png}
    \caption{Boxplot of log scores (20 repetitions, lower is better) for each 
             simulated scenario.  Each column represents a function/covariance 
             pair, and each row shows results for batch sizes of either 
             5 (top) or 15 (bottom) realizations. \textcolor{red}{(This figure needs udpating.)}}
    \label{fig:sims_logS}
\end{figure}

The competing methods we consider are an out-of-the-box DGP fit using the 
\texttt{deepgp} package \citep{sauer2023active}, a heteroskedastic GP fit using 
the \texttt{hetGP} package \citep{binois2018practical, binois2021hetgp}, as well 
as a deep process convolution (DPC) approach, which is utilized within Cosmic 
Emu \citep{moran2023mira}. \textcolor{red}{(@Steve - given the new figure, comment
on how these methods view the points as iid noise/heteroskedastic noise/etc.
Also need to comment on how $\Sigma_\epsilon$ is estimated for our method.  And
that there is no pre-processing of the weighted average, right?)}

The metrics we use to evaluate performance are mean squared error (MSE) and the 
log score, a proper scoring rule which takes both prediction and intervals into 
consideration \citep{gneiting2007strictly}. For both metrics, a lower value indicates 
better performance. Log score are shown in Figure \ref{fig:sims_logS}; our DGP.FCO 
model performs favorably against each of these current benchmark methods by
accounting for spatial dependence within our model, resulting in more accurate UQ.
MSE results, which do not address UQ, were comparable across competing methods; these results
can be found in Figure \ref{fig:sims_MSE}.
\textcolor{red}{(@Steve - this paragraph needs revising now that the figure is moved
to the appendix.)}

\subsection{CAMB Data}
\label{subsec:camb}

We next investigate model fits to several cosmological 
datasets from CAMB \citep{lewis2011CAMB}. These datasets contain power spectra based
on six-dimensional cosmological parameter settings. Similar to the Mira-Titan suite, the
CAMB dataset has multiple (sixty-four) batches of power spectra for each cosmology, with each batch 
containing multiple (fifteen) low-resolution spectra, and one high-resolution sprectum
\textcolor{red}{(@Steve - do you mean there are 64 cosmologies?)} 
Unlike the Mira-Titan suite, this dataset contains an infinite-resolution 
spectrum, which can be treated as the true spectrum for each cosmology,
allowing us to assess the accuracy of posterior mean estimates and effectiveness
of credible intervals. \textcolor{red}{(@Steve - refer to Figure 3 as a visual.  Comment on the
true power spectrum and the low/high res runs.)}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{CAMB_fit_model1.png}
    \caption{Example of DGP.FCO model fit for the first batch of model runs from the CAMB data, 
             with LOESS mean term subtracted. \textcolor{red}{(LOESS mean of what?  We need
             to officially say how things are centered.)} We can compare the orange lines 
             (posterior mean and dotted 95\% credible interval) to the light blue line,
             representing the infinite-resolution ``true" spectrum.}   
    \label{fig:fit_camb}
\end{figure}

We use 32 CAMB batches to train the DGP.FCO model and reserve the other 32 as a test set.
\textcolor{red}{(@Steve - I'm so confused.  We are not talking about PCA here.  Each
cosmology stands on its own.  We use the low/high res runs for training, and the true
spectrum for testing.)}
To imitate the role of the perturbation theory output of Mira-Titan, we anchor estimates of the CAMB
power spectrum at the infinite-resolution for $\log_{10}(k) < -1.7$, and then rely 
strictly on the low- and high-resolution runs for $k$ above this. 
\textcolor{red}{(Refer to the figure here as well to help explain?)}
We take a weighted
average of the CAMB runs and assume heteroskedastic errors in a similar fashion. 
\textcolor{red}{(Need details on how the weighted average is calculated.  Can
refer to previous section, but need to be specific.)}

To estimate $\Sigma_\epsilon$, we first use a log-log regression model to obtain 
precision estimates $\Lambda_\ell$ and $\Lambda_h$
for the low- and high-resolution runs respectively, as outlined in Section \ref{sec:data}. 
Similarly, we set $\Lambda_i=10^8$ \textcolor{red}{(this notation is no longer right.
Also why switch from $10^5$ to $10^8$?)} 
to illustrate high confidence in the infinite-resolution 
run for low $k$ values and incorporate these estimates within $\Sigma_\varepsilon$. 
With the precision information, we then estimate the Mat\'ern parameters for 
$\Sigma_\varepsilon$. \textcolor{red}{(Need more specifics.  Are we using a $\tau^2$ now?
5/2 still?  Maximum likelihood estimation?)}
For the CAMB data, lengthscale estimates are consistently 
around $3\times 10^{-7}$, evidence that we can simplify our covariance structure 
to contain no spatial dependence (compare low-resolution runs of Figure \ref{fig:fit_camb} 
with Figure \ref{fig:plot_data} \textcolor{red}{ - I don't understand what we are supposed
to see from this comparison.)}). We therefore specify $\Sigma_\varepsilon = 
(15\Lambda_\ell+\Lambda_h+\Lambda_i)^{-1}$ for the CAMB data.  

\textcolor{red}{(We need to fix the entire previous paragraph. How about we keep it short
and sweet and say we considered a Matern kernel, but found that the spatial correlation
decayed so quickly ($\theta\rightarrow 0$) that spatial dependence was not necessary.)}

After fitting the DGP.FCO model, an illustration of the posterior mean and its UQ can
be seen in Figure \ref{fig:fit_camb}. Notice that there are peaks where both the high-resolution
run and the weighted average are biased, but our posterior mean adjusts appropriately 
and has a more reliable estimate for the infinite-resolution run (the ``truth" in this setting). 
UQ is handled well, as precision increases with increasing $k$, which is captured in our
95\% credible intervals.

\textcolor{red}{(Where is the MSE/logscore across the 64 batches????  Are we comparing
to other methods?  As it stands, this is barely a "benchmark".  It is more of a "proof
of concept".)}

\subsection{Estimating Spectra with Mira-Titan Data}
\label{subsec:mira_fit}

\textcolor{red}{(@Steve - we've done a lot of edits up to this point.  Can
you revise this text now to fit in with the rest?  Need to refer to how the 
weighted average is calculated.
And the purpose of $\Sigma_\epsilon$.  But this is the first time Mira-Titan
specific details of $\Sigma_\epsilon$ will be mentioned.)}
From plots of the multiple low-resolution spectra (e.g., Figure \ref{fig:plot_data}), 
we find they vary smoothly about some mean $S$, suggesting that a dense covariance 
matrix $\Sigma_\varepsilon$ (accounting for spatial dependence) may outperform a 
diagonal covariance $\Lambda_\ell^{-1}$ for $\bar Y$. From Section \ref{sec:data},
we can incorporate domain knowledge from $\Lambda_p, \Lambda_\ell,$ and $\Lambda_h$ 
within our model. In previous work, we have modeled multiple candidates for 
$\Sigma_\varepsilon$ \citep{walsh2023bayesian} and found that a Mat\'ern covariance 
$\Sigma_\ell$ trained on the low-resolution runs (pre-scaled by the precision 
values and subtracting a LOESS-smoothed average) performs the best. 
We specify this structure within $\Sigma_\varepsilon$ and refer readers 
to \cite{walsh2023bayesian} for a more detailed exposition. This yields 
$\Sigma_\varepsilon=\left(\Lambda_p^{-1} + \Sigma_\ell + \Lambda_h^{-1}\right)^{-1}$, 
where $\Lambda_p, \Sigma_\ell^{-1}, \text{ and } \Lambda_h$ are all $n\times n$ 
and are 0 wherever the corresponding data type is biased. From here, we estimate 
$\tau_\ell, \theta_\ell$ with maximum likelihood, and input these within 
$\Sigma_\varepsilon$, which we use as an input to our model.

To train our hierarchical model, we initialize our hyperparameter estimates across 
all cosmologies by modeling the first (M001) with 50,000 MCMC runs, and use these 
as initial values for all cosmologies. Specifically, we save the last MCMC 
iteration of $W$, $\theta_w$ and $\theta_S$ as $W_0$, $\theta_{w0}$ and $\theta_{S0}$ 
respectively and use each as starting values for all 111 training cosmology fits, 
where each cosmology is fit with 10,000 MCMC runs (5,000 removed as burn-in and 
every 5th sample is kept, resulting in 1,000 posterior samples).

From these samples, we can estimate and quantify the uncertainty within each 
cosmology's average and latent layer $W$. Figure \ref{fig:plot_fit} shows an 
example of the uncertainty for our posterior mean for the first (of 111) training 
cosmologies; the posterior mean is subtracted in order to visualize this uncertainty. 
Figure \ref{fig:plot_warp} provides elliptical slice samples of $W$ along with the 
average warping. Some departure from stationarity is estimated in the higher $X$ 
(i.e., scaled $k$) values.

\begin{figure}[ht]
    \centering
    \includegraphics[width=6in]{plot_fit.png}
    \caption{95\% credible intervals for the power spectrum of model 1 (posterior mean 
             subtracted). Plots of the perturbation theory, low-resolution and high-resolution 
             runs are also shown, alongside the weighted average.
             \textcolor{red}{(This plot needs to be made fresh (not using the package
             function.  Adjust y-axis.  We don't need the yellow/red coloring.)}}
    \label{fig:plot_fit}
\end{figure}

\begin{figure}[ht]
   \centering
   \includegraphics[width=6in]{plot_warp_M001.png}
   \caption{Left: MCMC samples of $W$ for model M001 after burnin and thinning. 
            Right: Corresponding 95\% credible intervals for $W$, where departure 
            from the identity line represents nonstationary behavior.}
   \label{fig:plot_warp}
\end{figure}

\textcolor{red}{(This whole subsection is missing a point.  What is the point?
We don't know the truth, but what can we glean from this?  What does the warping
tell us?  Talk about the UQ...)}

\section{Prediction for Unobserved Cosmologies}
\label{sec:pred}

Upon obtaining the posterior means from each of the 111 training cosmologies, this 
section details our second contribution - the use of the Bayesian DGP.FCO model 
to predict the curve for held-out cosmologies. This is achieved with modeling the 
weights of different basis functions as GPs.

\subsection{Functional Prediction Model}
\label{subsec:pca}

Here, we begin with a $n \times m$ matrix composed of $m=111$ posterior means, 
each of length $n$, denoted by $\boldsymbol\eta$. To facilitate more efficient estimation, 
we use singular value decomposition \citep[SVD; e.g.,][]{banerjee2014linear}, 
where $\boldsymbol\eta = UDV^T$; $U$ and $V$ are orthogonal matrices of size $n \times n$ 
and $m\times m$, respectively. $D$ is a diagonal matrix containing the singular values. 
For this application, $\boldsymbol\eta$ has rank $r=\text{min}\{m,n\}=111$, which 
determines the number of non-zero elements in $D$. We find an alternative decomposition 
where $\Sigma$ is a diagonal matrix with the non-zero singular values of $\boldsymbol\eta$, 
and $U_1$ and $V_1$ are matrices with orthonormal columns of size $n_\eta \times r$ 
and $m \times r$, respectively. 

Following \cite{higdon2008computer, higdon2010estcosmo}, we equivalently decompose 
$\boldsymbol\eta$ into a principal component (PC) basis matrix 
$B^* = \frac{1}{\sqrt{m}}U_1\Sigma$ along with its corresponding weights 
$W^* = \sqrt{m}V_1$. Without loss of generality, we can perform this decomposition 
after an overall mean trend is removed. If we use $p_\eta < r$ PCs, this will reduce 
$B$ and $W$ to be the first $p_\eta$ columns of $B^*$ and $W^*$ respectively and 
result in an approximation where 

\begin{equation}
    \boldsymbol\eta= UDV^T = U_1\Sigma V_1^T \approx BW^T.
\end{equation}

Our goal is to predict the power spectrum for a held-out cosmology. 
For simplicity, we will denote these eight parameters for a given cosmology (see 
Section \ref{sec:data}) as $\psi \in \mathbb{R}^8$. 
Figure \ref{fig:mean_PCs_oneW} illustrates this decomposition with the estimated 
mean trend, the principal components contained in $B$, and one example of how the 
weight for the first PC will vary dependent on the first of $p_\psi=8$ cosmological 
parameters contained in $\psi$.

In the following subsections, we consider different modeling strategies for $W$, 
which will influence predictions and sensitivity analyses based on $\boldsymbol\eta$.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{mean_PCs_oneW.png}
    \caption{The estimated mean trend of the 111 posterior means (left), the principal 
    components contained in $B$ (middle), and an illustration of how the weights 
    for the first PC will change as the first cosmological parameter varies (right) 
    \textcolor{red}{This last plot is wonky because it was made with only the 6 test 
    cosmologies, not a large uniform or FF design, Steve can update this}.}
    \label{fig:mean_PCs_oneW}
\end{figure}



% This is old: switched to SEPIA
% We assume a powered exponential kernel for the Gaussian process and employ 
% \texttt{GPfit} to perform a multi-start gradient based search for GP's hyperparameters 
% \citep{macdonald2015gpfit}. 
In alignment with \cite{heitmann2009coyote} and \cite{higdon2010estcosmo}, we use 
GPs to model the principal components' weights. For direct comparison alongside
\cite{moran2023mira}, we employ a Python implementation of this approach called 
SEPIA \citep{gattiker2020sepia}. That is, the $i$th vector of PC weights $w_i(\psi)$, 
$i \in \{1,\ldots,p_\eta\}$, is modeled as a zero-mean Gaussian process with a 
squared exponential (i.e., Gaussian) covariance function:
\[
w_i(\psi) \sim GP\left(0,\ \frac{1}{\lambda_{z_i}} R^{(i)} + \frac{1}{\lambda_{s_i}} I \right),
\]
with covariance function
\[
R^{(i)}_{uv} = \exp\left(-\sum_{k=1}^{p_\psi} \beta_{ik} (x_{uk} - x_{vk})^2 \right),
\]
where $\beta_{ik}$ is the inverse squared lengthscale for the $k$th input dimension, $\lambda_{z_i}$ is the marginal precision for $w_i(\psi)$, and $\lambda_{s_i}$ is the nugget precision (set to zero if no nugget is used).

Using these trained GPs from the PCs, we predict the spectra for unobserved cosmologies.

\subsection{Predicting Spectra for CAMB Data}
\label{subsec:camb_pred}

From our 32 posterior means using DGP.FCO, these are input into SEPIA in order to predict power spectra
for the 32 test cosmologies. With the infinite-resolution output, we have a sense of the ``best-case" 
predictions we can have (i.e., if we trained with the 32 true power spectra, as opposed to our 
estimated posterior means). In Figure \ref{fig:pca_preds_v_camb}, we see comparisons of the heldout 
infinite resolution alongside two predictions: one based on DGP.FCO and the ``best-case" scenario using the
infinite-resolution spectra of the training set. There is a high level of agreement between the pairs
of predictions across cosmologies. Upon comparing MSEs for each of these prediction scenarios 
(Figure \ref{fig:mse_camb}, most are very similar across the two groups (with the two most difficult 
predictions being the exceptions), suggesting that overall DGP.FCO is estimating the true spectra 
for each batch well.

\begin{figure}
    \centering
    \includegraphics[width=4in]{preds_diff1_4_8.jpg}
    \caption{Predictions for 16 of the 32 test cosmologies after centering and scaling. 
             The interpolated infinite resolution run is shown in black, the prediction 
             (trained on the infinite resolution) is in blue and the prediction from 
             the DGP.FCO posterior mean is in red.}   
    \label{fig:pca_preds_v_camb}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=3in]{mse_dot.jpg}
    \caption{Comparison of MSE for CAMB predictions, when training with DGP.FCO posterior 
             means (left), and training with the ``true" infinite-resolution spectra (right).}   
    \label{fig:mse_camb}
\end{figure}

\subsection{Predicting Spectra from Mira-Titan Data}
\label{subsec:mira_pred}

Here we show prediction results for 6 held-out cosmologies. We compare our method 
with Cosmic Emu \citep{moran2023mira}, the emulator constructed using the full suite 
of 111 Mira-Titan model runs. Cosmic Emu uses a Bayesian approach where the smooth 
spectrum for each cosmology is modeled with a process convolution on Brownian motion. 
Nonstationarity is permitted through modeling the bandwidth parameter with a process 
convolution as well; this composition is referred to as a deep process convolution 
\citep{moran2024dpc}.

Both Cosmic Emu and DGP.FCO are capable of modeling a true underlying functions based 
upon multiple functional realizations, but our approach utilizes DGPs within a 
hierarchical model in lieu of deep process convolutions. After obtaining the estimated 
smooth spectra from the training cosmologies, each method utilizes GPs in order to 
estimate the weights of the PCs from the estimated spectra. Below, we compare prediction 
performance between Cosmic Emu and DGP.FCO for the 6 held-out cosmologies. 
\textcolor{magenta}{In addition, we can also predict over a large uniform or full 
factorial design to obtain estimated main effects for each cosmological parameter in 
$\psi$, interactions amongst the $p_\psi=8$ parameters, and decompose the overall 
variation by main effects, two-way interactions, and so on. Should this be included?}

Plots for the average root mean squared error (RMSE) for each prediction method over the 
6 cosmologies and each $k$ value are shown in Figure \ref{fig:plot_rmse_k}. Comparisons 
of the spectrum estimation for training cosmologies are shown as well (using RMSE against 
the weighted average of observations). For predictions, DGP.FCO achieves the greatest 
reduction in RMSE in the region where perturbation theory and the low-resolution runs 
are deemed unbiased. For the region where only the high-resolution run is unbiased, 
Cosmic Emu has a lower average RMSE. Over all $k$ values and predictions, DGP.FCO has 
an average RMSE of 0.0089 and Cosmic Emu has an average RMSE of 0.0106. Our RMSE is 
lower at 56\% of $k$ values considered. The individual predictions for each method and 
cosmology are shown in Figure \ref{fig:plot_pred_1to6}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=6in]{rmse_by_k.png}
    \caption{Left: Average RMSE of each prediction method across all $k$ values. 
             Right: Average RMSE for each method when using the held-out computer 
             model runs to train the model. In each case, the truth is assumed to 
             be the weighted average of the computer model runs.}
    \label{fig:plot_rmse_k}
\end{figure}

% \begin{figure}[ht]
%     \centering
%     \includegraphics[width=6in]{rmse_box.png}
%     \caption{Boxplot of all RMSEs of each method across all six test models. 
%.             From top to bottom: box plots for our training method, process 
%              convolution training method, Cosmic EMU predictions, and our DGP-PC predictions.}
%     \label{fig:plot_rmse_box}
% \end{figure}

\section{Discussion}
\label{sec:disc}

In this work, we propose a novel Bayesian hierarchical model which utilizes DGPs 
in order to estimate a smooth underlying function from correlated functional observations 
(as cosmological computer model runs). In addition to the compositional form of the DGP, 
we include a third component modeling the correlated errors for each spectrum. 
With all smooth spectra estimated from the training set of 111 batches of model runs, 
we can predict spectra for unobserved cosmologies.

Multiple avenues for future research emerge: in addition to estimating dark matter 
power spectra, batches of hydrodynamical simulations exist, and this method could 
easily be adapted to handle such datasets. Other applications outside of cosmology 
can be explored, wherever multiple functional outputs exist, perhaps with spatial 
correlation (for example, observing multiple tropical cyclone forecasts). More detailed 
sensitivity analyses for the cosmological parameters can be explored to gain insights 
into how each of these parameters interact, and which are most significant. From a 
modeling perspective, changes to the model could include modeling the latent layer 
$W$ jointly across different cosmologies, as well as considering different redshift 
values other than $z=0$. Leveraging a hybrid model between DGP.FCO and Cosmic Emu 
may also help to obtain accurate estimates on the lower and higher ends of $k$ values, 
respectively. Additionally, Bayesian smoothing spline ANOVA (BSS-ANOVA) or other methods 
could be compared in addition to DGPs. 

\section{Acknowledgments}
\label{sec:ack}

\textcolor{red}{This work was in part supported by the U.S. Department
of Energy, Office of Science, Office of Advanced Scientific Computing Research, 
Scientific Discovery through Advanced Computing (SciDAC) program through 
Grant 420453 "Enabling Cosmic Discoveries in the Exascale Era."}

The authors are pleased to acknowledge Advanced Research Computing at Virginia Tech 
(\url{https://arc.vt.edu/}) as well as the Shared Computing Cluster (SCC) administered
by Boston University's Research Computing Services (\url{www.bu.edu/tech/support/research/})
for providing computational resources and technical support that have contributed 
to the results reported within this paper.

\appendix
\renewcommand{\thesection}{Appendix \Alph{section}}

\section{Integrated Likelihood}
\label{sec:apdx_int_lik}
Here, we establish that under the model:

$$
\begin{aligned}
Y_i|S,W &\sim N\big(S, \Sigma_\varepsilon\big), \quad i \in \{1,\dots, r\}\\
S|W &\sim N\big(\boldsymbol{\mu}, \Sigma_S(w,w')\big)\\
W &\sim N\big(\mathbf{0}, \Sigma_W(x,x')\big) \\
\end{aligned}
$$

We can obtain the integrated likelihood $p(Y_i|W)=\int p(Y_i|S,W)p(S|W) dS$, 
with the following calculations:
$$
\begin{aligned}
p(Y_i|W) &= \int p(Y_i|S,W)p(S|W)dS \\
&\propto \int\exp\left(-\frac{1}{2} \left[Y_i^T\Sigma_\varepsilon^{-1} Y_i 
- 2Y_i^T\Sigma_\varepsilon^{-1} S + S^T \Sigma_\varepsilon^{-1} S + S^T \Sigma_S^{-1} S 
-2S^T \Sigma_S^{-1} \boldsymbol{\mu} 
+ \boldsymbol{\mu}^T \Sigma_S^{-1} \boldsymbol{\mu} \right]\right)dS \\
\end{aligned}
$$

If we focus only on terms containing $S$, we have 
$$
\begin{aligned}
    \exp\Big(-\frac{1}{2} \big[S^T &(\Sigma_\varepsilon^{-1}+\Sigma_S^{-1}) S 
    -2S^T (\Sigma_S^{-1} \boldsymbol{\mu} + \Sigma_\varepsilon^{-1} Y_i) \big]\Big) \\
&= \exp\left(-\frac{1}{2} \left[S^T (\Sigma_\varepsilon^{-1}+\Sigma_S^{-1}) S 
-2S^T (\Sigma_\varepsilon^{-1}+\Sigma_S^{-1})(\Sigma_\varepsilon^{-1}
+\Sigma_S^{-1})^{-1}(\Sigma_S^{-1} \boldsymbol{\mu} + \Sigma_\varepsilon^{-1} Y_i) \right]\right)
\end{aligned}
$$

To complete the square, we add and subtract $(\Sigma_S^{-1} \boldsymbol{\mu} 
+ \Sigma_\varepsilon^{-1} Y_i)^T(\Sigma_\varepsilon^{-1}+\Sigma_S^{-1})^{-1}
(\Sigma_S^{-1} \boldsymbol{\mu} + \Sigma_\varepsilon^{-1} Y_i)$, 
which then gives the kernel for $S \sim N\left((\Sigma_\varepsilon^{-1}
+\Sigma_S^{-1})^{-1}(\Sigma_S^{-1} \boldsymbol{\mu} + \Sigma_\varepsilon^{-1} Y_i), 
(\Sigma_\varepsilon^{-1}+\Sigma_S^{-1})^{-1} \right)$. 
This removes the integral and leaves us with the following terms for $Y_i|W$:
$$
\begin{aligned}
&\exp\Big(-\frac{1}{2}\big[Y_i^T\Sigma_\varepsilon^{-1} Y + 
\boldsymbol{\mu}^T\Sigma_S^{-1} \boldsymbol{\mu} - (\Sigma_S^{-1} \boldsymbol{\mu} + 
\Sigma_\varepsilon^{-1} Y_i)^T(\Sigma_\varepsilon^{-1}+\Sigma_S^{-1})^{-1} 
(\Sigma_S^{-1} \boldsymbol{\mu} + \Sigma_\varepsilon^{-1} Y_i)\big]\Big) \\
&= \exp\Big(-\frac{1}{2}\big[Y_i^T\big(\Sigma_\varepsilon^{-1} - 
\Sigma_\varepsilon^{-1}(\Sigma_\varepsilon^{-1}+\Sigma_S^{-1})^{-1}\Sigma_\varepsilon^{-1}\big)Y_i 
-2Y_i^T \Sigma_\varepsilon^{-1}(\Sigma_\varepsilon^{-1}+\Sigma_S^{-1})^{-1}\Sigma_S^{-1} \boldsymbol{\mu} \\
&\qquad \qquad \qquad + \boldsymbol{\mu}^T (\Sigma_S^{-1} - \Sigma_S^{-1}(\Sigma_\varepsilon^{-1}
+\Sigma_S^{-1})^{-1}\Sigma_S^{-1}) \boldsymbol{\mu}\big]\Big) \\
&= \exp\Big(-\frac{1}{2}\big((Y_i-\boldsymbol{\mu})^T(\Sigma_\varepsilon+\Sigma_S)^{-1}
(Y_i-\boldsymbol{\mu}) \big)\Big)
\end{aligned}
$$

With the last equality resulting from the use of the Sherman–Morrison–Woodbury formula, 
yielding $\big(\Sigma_\varepsilon^{-1} - \Sigma_\varepsilon^{-1}(\Sigma_\varepsilon^{-1}+
\Sigma_S^{-1})^{-1}\Sigma_\varepsilon^{-1} = (\Sigma_S^{-1} - \Sigma_S^{-1}
(\Sigma_\varepsilon^{-1}+\Sigma_S^{-1})^{-1}\Sigma_S^{-1}) = (\Sigma_\varepsilon+\Sigma_S)^{-1}$. 
We also use the fact that $\Sigma_\varepsilon^{-1}(\Sigma_\varepsilon^{-1}+
\Sigma_S^{-1})^{-1}\Sigma_S^{-1} = (\Sigma_\varepsilon + \Sigma_S)^{-1}$, 
which holds since it can be shown that 
$[\Sigma_S(\Sigma_\varepsilon^{-1}+\Sigma_S^{-1})\Sigma_\varepsilon](\Sigma_\varepsilon+\Sigma_S)
=(\Sigma_\varepsilon+\Sigma_S)(\Sigma_\varepsilon+\Sigma_S)$.

Therefore, we have that $Y_i|W \sim N\big(\boldsymbol{\mu}, \Sigma_S(w,w')+\Sigma_\varepsilon(w,w')\big)$.

\section{Conditional Distribution of Power Spectrum, Given Weighted Average}
\label{sec:apdx_SgivenY}

From our model specification, we have the following:

\[
S \sim \mathcal{N}(\boldsymbol{\mu}, \Sigma_S)
\]
\[
\bar{Y} \mid S \sim \mathcal{N}(S, \Sigma_\epsilon)
\]

Then, to find the distribution of $S|\bar{Y}$, we apply Bayes' Theorem below, 
where $\propto$ indicates proportionality:
\[
P(S \mid \bar{Y}) \propto P(\bar{Y} \mid S) P(S)
\]

\[
\propto \exp\left(-\tfrac{1}{2} (\bar{Y} - S)^T \Sigma_\epsilon^{-1} (\bar{Y} - S) \right) 
\cdot \exp\left(-\tfrac{1}{2} (S - \boldsymbol{\mu})^T \Sigma_S^{-1} (S - \boldsymbol{\mu})\right)
\]

\[
\propto \exp\left(-\tfrac{1}{2} \left[ \bar{Y}^T \Sigma_\epsilon^{-1} \bar{Y} 
- 2 S^T \Sigma_\epsilon^{-1} \bar{Y} + S^T \Sigma_\epsilon^{-1} S + S^T \Sigma_S^{-1} S 
- 2 S^T \Sigma_S^{-1} \boldsymbol{\mu} + \boldsymbol{\mu}^T \Sigma_S^{-1} \boldsymbol{\mu} \right] \right)
\]

\[
\propto \exp\left( -\tfrac{1}{2} \left[ S^T (\Sigma_\epsilon^{-1} + \Sigma_S^{-1}) S 
- 2 S^T (\Sigma_\epsilon^{-1} \bar{Y} + \Sigma_S^{-1} \boldsymbol{\mu}) \right] \right)
\]

From properties of the multivariate normal distribution \citep[e.g., Equation 7.1 of][]{hoff2009first},
we can establish that the mean and covariance of $S|\bar{Y}$ will be $\boldsymbol{m}$
and $C$ respectively, where we can solve for these values with:

\[
C^{-1} = \Sigma_\epsilon^{-1} + \Sigma_S^{-1}
\]
\[
C^{-1} \boldsymbol{m} = \Sigma_\epsilon^{-1} \bar{Y} + \Sigma_S^{-1} \boldsymbol{\mu}
\]

Then,
\[
C = (\Sigma_\epsilon^{-1} + \Sigma_S^{-1})^{-1}
\]
\[
\boldsymbol{m} = \left( \Sigma_S^{-1} + \Sigma_\epsilon^{-1} \right)^{-1} 
\left( \Sigma_\epsilon^{-1} \bar{Y} + \Sigma_S^{-1} \boldsymbol{\mu} \right)
= C \cdot \left( \Sigma_\epsilon^{-1} \bar{Y} + \Sigma_S^{-1} \boldsymbol{\mu} \right)
\]

Therefore, we have the result that $S|\bar{Y} \sim \mathcal{N}(\boldsymbol{m}, C)$.


\section{Mira-Titan Predictive Plots}
\label{sec:apdx_mira_plots}

\textcolor{magenta}{The different appendices from dissertation as necessary. 
Can also put details of dataset in supplementary material.} 
\textcolor{red}{Fix references as necessary, e.g. Moran et al. 2024.}

\begin{figure}[ht]
    \centering
    \includegraphics[width=6in]{pred_1to6.png}
    \caption{Results of all six predictions for both methods on the held-out 
    cosmologies (weighted average subtracted). CosmicEMU is dashed, DGP.FCO is dotted, 
    and solid gray lines show results of held-out computer model runs.}
    \label{fig:plot_pred_1to6}
\end{figure}

\section{Simulation Study Additional Results}
\label{sec:apdx_sims}

\begin{figure}
    \centering
    \includegraphics[width=6in]{sims_MSE.png}
    \caption{Boxplot of MSEs across two different functions and covariance settings 
             (lower is better). For each case, the boxplot is constructed from 20 
             random batches were simulated. Each column represents a function/variance 
             specification pair, and each row shows results for batch sizes of 
             either 5 (top) or 15 (bottom).}    
    \label{fig:sims_MSE}
\end{figure}

\bibliographystyle{jasa}
\bibliography{references}

\end{document}
